#!/usr/bin/env python3
"""
Q-SiT-mini vs One-Align å¯¹æ¯”æµ‹è¯•
å¯¹åŒæ · 100 å¼ ç…§ç‰‡è¯„åˆ†ï¼Œæ¯”è¾ƒæ’åºä¸€è‡´æ€§
"""

import os
import sys
import time
import csv
from pathlib import Path
from PIL import Image
import torch
import numpy as np
from tqdm import tqdm

sys.path.insert(0, str(Path(__file__).parent))


def wa5(logits):
    """åŠ æƒå¹³å‡è®¡ç®—åˆ†æ•° (0-1)"""
    logprobs = np.array([logits["Excellent"], logits["Good"], logits["Fair"], logits["Poor"], logits["Bad"]])
    probs = np.exp(logprobs) / np.sum(np.exp(logprobs))
    return np.inner(probs, np.array([1, 0.75, 0.5, 0.25, 0]))


def load_qsit_mini():
    """åŠ è½½ Q-SiT-mini æ¨¡å‹"""
    print("\n" + "=" * 60)
    print("ğŸš€ åŠ è½½ Q-SiT-mini æ¨¡å‹...")
    print("=" * 60)
    
    from transformers import AutoProcessor, LlavaOnevisionForConditionalGeneration, AutoTokenizer
    
    model_id = "zhangzicheng/q-sit-mini"
    
    model = LlavaOnevisionForConditionalGeneration.from_pretrained(
        model_id,
        torch_dtype=torch.float16,
        low_cpu_mem_usage=True,
    ).to("mps")  # Apple Silicon
    
    processor = AutoProcessor.from_pretrained(model_id)
    tokenizer = AutoTokenizer.from_pretrained(model_id)
    
    # å®šä¹‰è¯„åˆ† token
    toks = ["Excellent", "Good", "Fair", "Poor", "Bad"]
    ids_ = [id_[0] for id_ in tokenizer(toks)["input_ids"]]
    
    print("âœ… Q-SiT-mini åŠ è½½å®Œæˆ\n")
    
    return model, processor, tokenizer, toks, ids_


def score_with_qsit(model, processor, tokenizer, toks, ids_, image, task="quality"):
    """ä½¿ç”¨ Q-SiT-mini è¯„åˆ†"""
    
    if task == "quality":
        prompt_text = "Assume you are an image quality evaluator. \nYour rating should be chosen from the following five categories: Excellent, Good, Fair, Poor, and Bad (from high to low). \nHow would you rate the quality of this image?"
        prefix_text = "The quality of this image is "
    else:
        prompt_text = "Assume you are an image aesthetic evaluator. \nYour rating should be chosen from the following five categories: Excellent, Good, Fair, Poor, and Bad (from high to low). \nHow would you rate the aesthetic of this image?"
        prefix_text = "The aesthetic of this image is "
    
    conversation = [
        {
            "role": "user",
            "content": [
                {"type": "text", "text": prompt_text},
                {"type": "image"},
            ],
        },
    ]
    
    prompt = processor.apply_chat_template(conversation, add_generation_prompt=True)
    inputs = processor(images=image, text=prompt, return_tensors='pt').to("mps", torch.float16)
    
    # æ·»åŠ åŠ©æ‰‹å‰ç¼€
    prefix_ids = tokenizer(prefix_text, return_tensors="pt")["input_ids"].to("mps")
    inputs["input_ids"] = torch.cat([inputs["input_ids"], prefix_ids], dim=-1)
    inputs["attention_mask"] = torch.ones_like(inputs["input_ids"])
    
    # ç”Ÿæˆè¯„åˆ† token
    with torch.inference_mode():
        output = model.generate(
            **inputs,
            max_new_tokens=1,
            output_logits=True,
            return_dict_in_generate=True,
        )
    
    # æå– logits å¹¶è®¡ç®—åˆ†æ•°
    last_logits = output.logits[-1][0]
    logits_dict = {tok: last_logits[id_].item() for tok, id_ in zip(toks, ids_)}
    score = wa5(logits_dict) * 100  # è½¬æ¢ä¸º 0-100
    
    return score


def main():
    test_dir = "/Users/jameszhenyu/Desktop/NEWTEST_preprocessed_1024"
    
    # æ”¶é›†å›¾ç‰‡
    extensions = {".jpg", ".jpeg", ".png"}
    image_files = []
    for f in os.listdir(test_dir):
        if os.path.splitext(f)[1].lower() in extensions:
            image_files.append(os.path.join(test_dir, f))
    
    image_files = sorted(image_files)[:100]  # å–å‰ 100 å¼ 
    
    print(f"\nğŸ“ æµ‹è¯•ç›®å½•: {test_dir}")
    print(f"   æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡\n")
    
    # åŠ è½½ Q-SiT-mini
    model, processor, tokenizer, toks, ids_ = load_qsit_mini()
    
    # è¯„åˆ†
    print("\n" + "=" * 60)
    print("ğŸ”¬ Q-SiT-mini è¯„åˆ†ä¸­...")
    print("=" * 60 + "\n")
    
    results = []
    start_total = time.time()
    
    for img_path in tqdm(image_files, desc="è¯„åˆ†è¿›åº¦"):
        filename = os.path.basename(img_path)
        
        try:
            image = Image.open(img_path).convert("RGB")
            
            start = time.time()
            quality_score = score_with_qsit(model, processor, tokenizer, toks, ids_, image, "quality")
            aesthetic_score = score_with_qsit(model, processor, tokenizer, toks, ids_, image, "aesthetic")
            elapsed = time.time() - start
            
            # ç»¼åˆåˆ† (å’Œ One-Align ç›¸åŒæƒé‡: Q40% + A60%)
            total_score = quality_score * 0.4 + aesthetic_score * 0.6
            
            results.append({
                "file": filename,
                "quality": quality_score,
                "aesthetic": aesthetic_score,
                "total": total_score,
                "time": elapsed,
            })
            
        except Exception as e:
            tqdm.write(f"âŒ {filename}: {e}")
            results.append({
                "file": filename,
                "quality": 0,
                "aesthetic": 0,
                "total": 0,
                "time": 0,
                "error": str(e),
            })
    
    total_time = time.time() - start_total
    
    # ä¿å­˜ç»“æœ
    output_csv = os.path.join(test_dir, "qsit_mini_results.csv")
    with open(output_csv, "w", newline="", encoding="utf-8") as f:
        writer = csv.DictWriter(f, fieldnames=["file", "quality", "aesthetic", "total", "time", "error"])
        writer.writeheader()
        for r in results:
            writer.writerow(r)
    
    print(f"\nâœ… ç»“æœå·²ä¿å­˜: {output_csv}")
    
    # ç»Ÿè®¡
    valid_results = [r for r in results if "error" not in r]
    avg_time = sum(r["time"] for r in valid_results) / len(valid_results) if valid_results else 0
    
    print(f"\nğŸ“Š ç»Ÿè®¡:")
    print(f"   æˆåŠŸ: {len(valid_results)}/{len(results)}")
    print(f"   æ€»è€—æ—¶: {total_time:.1f}s")
    print(f"   å¹³å‡è€—æ—¶: {avg_time:.2f}s/å¼ ")
    
    # åˆ†æ•°åˆ†å¸ƒ
    if valid_results:
        totals = [r["total"] for r in valid_results]
        print(f"\n   åˆ†æ•°åˆ†å¸ƒ:")
        print(f"   æœ€é«˜: {max(totals):.1f}")
        print(f"   æœ€ä½: {min(totals):.1f}")
        print(f"   å¹³å‡: {sum(totals)/len(totals):.1f}")


if __name__ == "__main__":
    main()
