#!/usr/bin/env python3
"""
One-Align å¤šç»´åº¦è¯„åˆ†æµ‹è¯•
ä½¿ç”¨å·²æœ‰çš„ OneAlignScorer ä¸­çš„æ­£ç¡®æ¨¡å‹åŠ è½½æ–¹å¼
"""

import os
import sys
import time
from pathlib import Path
from PIL import Image
import torch

sys.path.insert(0, str(Path(__file__).parent))
from raw_converter import is_raw_file, raw_to_jpeg
from one_align_scorer import OneAlignScorer

def prepare_image(image_path: str) -> tuple[str, bool]:
    """å‡†å¤‡å›¾ç‰‡"""
    if not is_raw_file(image_path):
        return image_path, False

    import tempfile
    temp_path = os.path.join(
        tempfile.gettempdir(),
        f"test_multi_{os.path.basename(image_path)}.jpg"
    )
    extracted = raw_to_jpeg(image_path, temp_path)

    img = Image.open(extracted)
    max_size = 1920
    w, h = img.size
    if w > max_size or h > max_size:
        ratio = min(max_size / w, max_size / h)
        img = img.resize((int(w * ratio), int(h * ratio)), Image.Resampling.LANCZOS)
        img.save(extracted, "JPEG", quality=95)

    return extracted, True


def main():
    test_dir = "/Users/jameszhenyu/Desktop/NEWTEST/4"
    
    # æ”¶é›†å›¾ç‰‡
    extensions = {".jpg", ".jpeg", ".png", ".arw", ".cr2", ".cr3", ".nef", ".dng", ".raf"}
    image_files = []
    for f in os.listdir(test_dir):
        if os.path.splitext(f)[1].lower() in extensions:
            image_files.append(os.path.join(test_dir, f))
    
    print(f"\nğŸ“ æµ‹è¯•ç›®å½•: {test_dir}")
    print(f"   æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡\n")
    
    # ä½¿ç”¨å·²æœ‰çš„ scorer åŠ è½½æ¨¡å‹ï¼ˆæ­£ç¡®å¤„ç†äº†å…¼å®¹æ€§é—®é¢˜ï¼‰
    scorer = OneAlignScorer()
    scorer.load_model()
    
    model = scorer.model  # è·å–åŠ è½½å¥½çš„æ¨¡å‹
    
    # æµ‹è¯•æ‰€æœ‰å¯èƒ½çš„ task_ å‚æ•°
    tasks = [
        # æ ¸å¿ƒæŒ‡æ ‡
        "quality",           # è´¨é‡
        "aesthetics",        # ç¾å­¦
        
        # æŠ€æœ¯æŒ‡æ ‡
        "sharpness",         # é”åº¦
        "noise level",       # å™ªç‚¹
        "exposure",          # æ›å…‰
        "dynamic range",     # åŠ¨æ€èŒƒå›´
        "focus",             # å¯¹ç„¦
        "clarity",           # æ¸…æ™°åº¦
        
        # æ„å›¾æŒ‡æ ‡
        "composition",       # æ„å›¾
        "balance",           # å¹³è¡¡
        "framing",           # å–æ™¯
        "visual flow",       # è§†è§‰æµåŠ¨
        
        # å…‰çº¿æŒ‡æ ‡
        "lighting",          # å…‰çº¿
        "contrast",          # å¯¹æ¯”åº¦
        "color",             # è‰²å½©
        "color harmony",     # è‰²å½©å’Œè°
        "saturation",        # é¥±å’Œåº¦
        "white balance",     # ç™½å¹³è¡¡
        
        # æƒ…æ„ŸæŒ‡æ ‡
        "mood",              # æƒ…ç»ª
        "atmosphere",        # æ°›å›´
        "emotional impact",  # æƒ…æ„Ÿå†²å‡»
        
        # ç»¼åˆæŒ‡æ ‡
        "overall appeal",    # æ•´ä½“å¸å¼•åŠ›
        "storytelling",      # å™äº‹æ€§
        "originality",       # åŸåˆ›æ€§
        "professionalism",   # ä¸“ä¸šåº¦
    ]
    
    # åªå¤„ç†ç¬¬ä¸€å¼ å›¾æ¥æµ‹è¯•ï¼ˆç”¨ JPGï¼Œé¿å… RAW å¤„ç†æ—¶é—´å¹²æ‰°ï¼‰
    # æ‰¾ JPG æ–‡ä»¶
    jpg_files = [f for f in image_files if f.lower().endswith('.jpg')]
    if jpg_files:
        test_image = jpg_files[0]
    else:
        test_image = image_files[0]
    
    print(f"\nğŸ“· æµ‹è¯•å›¾ç‰‡: {os.path.basename(test_image)}")
    
    processed_path, is_temp = prepare_image(test_image)
    print(f"   {'[RAWâ†’JPEG æå–]' if is_temp else '[ç›´æ¥è¯»å–]'}")
    
    image = Image.open(processed_path).convert("RGB")
    
    print(f"\n{'='*70}")
    print("ğŸ”¬ æµ‹è¯•æ‰€æœ‰ task_ å‚æ•°")
    print(f"{'='*70}")
    
    results = {}
    with torch.inference_mode():
        for task in tasks:
            start = time.time()
            try:
                score = model.score([image], task_=task, input_="image")
                score_value = float(score[0]) if isinstance(score, (list, torch.Tensor)) else float(score)
                elapsed = time.time() - start
                results[task] = (score_value, elapsed)
                print(f"  {task:25s}: {score_value:.2f}/5.0  ({score_value*20:.0f}/100)  [{elapsed:.2f}s]")
            except Exception as e:
                elapsed = time.time() - start
                results[task] = (None, elapsed)
                print(f"  {task:25s}: âŒ é”™è¯¯ - {e}  [{elapsed:.2f}s]")
    
    # æ¸…ç†
    if is_temp and os.path.exists(processed_path):
        os.remove(processed_path)
    
    # ç»Ÿè®¡
    print(f"\n{'='*70}")
    print("ğŸ“Š ç»Ÿè®¡")
    print(f"{'='*70}")
    
    valid_results = [(t, s, e) for t, (s, e) in results.items() if s is not None]
    if valid_results:
        avg_time = sum(e for _, _, e in valid_results) / len(valid_results)
        print(f"  æˆåŠŸç‡: {len(valid_results)}/{len(tasks)}")
        print(f"  å¹³å‡è€—æ—¶: {avg_time:.2f}s / é¡¹")
        print(f"  æ€»è€—æ—¶: {sum(e for _, _, e in valid_results):.1f}s")
        
        # åˆ†æ•°åˆ†å¸ƒ
        scores = sorted([(t, s) for t, s, _ in valid_results], key=lambda x: -x[1])
        print(f"\n  ğŸ“ˆ åˆ†æ•°æ’åº (é«˜â†’ä½):")
        for t, s in scores:
            bar = "â–ˆ" * int(s * 4)
            print(f"    {t:25s}: {s:.2f}  {bar}")


if __name__ == "__main__":
    main()
