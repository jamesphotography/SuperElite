#!/usr/bin/env python3
"""
æµ‹è¯• q-future/co-instruct çš„å¯¹è¯èƒ½åŠ›
å¯ä»¥ï¼š1) åˆ†æå•å¼ å›¾ç‰‡ 2) å¯¹æ¯”ä¸¤å¼ å›¾ç‰‡
"""

import os
import sys
import time
from pathlib import Path
from PIL import Image
import torch

sys.path.insert(0, str(Path(__file__).parent))
from raw_converter import is_raw_file, raw_to_jpeg


def prepare_image(image_path: str) -> tuple[str, bool]:
    """å‡†å¤‡å›¾ç‰‡"""
    if not is_raw_file(image_path):
        return image_path, False

    import tempfile
    temp_path = os.path.join(
        tempfile.gettempdir(),
        f"test_coinstruct_{os.path.basename(image_path)}.jpg"
    )
    extracted = raw_to_jpeg(image_path, temp_path)

    img = Image.open(extracted)
    max_size = 1920
    w, h = img.size
    if w > max_size or h > max_size:
        ratio = min(max_size / w, max_size / h)
        img = img.resize((int(w * ratio), int(h * ratio)), Image.Resampling.LANCZOS)
        img.save(extracted, "JPEG", quality=95)

    return extracted, True


def main():
    test_dir = "/Users/jameszhenyu/Desktop/NEWTEST/4"
    
    # æ”¶é›†å›¾ç‰‡
    extensions = {".jpg", ".jpeg", ".png", ".arw", ".cr2", ".cr3", ".nef", ".dng", ".raf"}
    image_files = []
    for f in os.listdir(test_dir):
        if os.path.splitext(f)[1].lower() in extensions:
            image_files.append(os.path.join(test_dir, f))
    
    print(f"\nğŸ“ æµ‹è¯•ç›®å½•: {test_dir}")
    print(f"   æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡\n")
    
    # åŠ è½½ co-instruct æ¨¡å‹
    print("=" * 70)
    print("ğŸš€ åŠ è½½ co-instruct æ¨¡å‹...")
    print("=" * 70)
    
    from transformers import AutoModelForCausalLM
    
    model = AutoModelForCausalLM.from_pretrained(
        "q-future/co-instruct",
        trust_remote_code=True,
        torch_dtype=torch.float16,
        attn_implementation="eager",
        device_map={"": "mps"}  # Apple Silicon
    )
    
    print("âœ… co-instruct åŠ è½½å®Œæˆ\n")
    
    # å‡†å¤‡æ‰€æœ‰å›¾ç‰‡
    images = []
    filenames = []
    temp_files = []
    
    for img_path in image_files:
        processed_path, is_temp = prepare_image(img_path)
        img = Image.open(processed_path).convert("RGB")
        images.append(img)
        filenames.append(os.path.basename(img_path))
        if is_temp:
            temp_files.append(processed_path)
        print(f"   åŠ è½½: {filenames[-1]} {'[RAWâ†’JPEG]' if is_temp else ''}")
    
    # æµ‹è¯•æç¤ºåˆ—è¡¨
    single_image_prompts = [
        ("è´¨é‡é—®é¢˜æ£€æµ‹", "USER: The image: <|image|> Which quality issues exist in this image? List all problems like blur, noise, exposure issues, etc. ASSISTANT:"),
        ("æ•´ä½“è´¨é‡è¯„ä»·", "USER: The image: <|image|> Describe the overall quality of this landscape photograph. Is it professional quality? ASSISTANT:"),
        ("æŠ€æœ¯åˆ†æ", "USER: The image: <|image|> Analyze the technical aspects: sharpness, exposure, dynamic range, color accuracy. ASSISTANT:"),
        ("æ„å›¾åˆ†æ", "USER: The image: <|image|> How is the composition of this photograph? Describe the use of foreground, leading lines, and balance. ASSISTANT:"),
        ("ä¼˜ç¼ºç‚¹æ€»ç»“", "USER: The image: <|image|> What are the strengths and weaknesses of this photograph? Be specific. ASSISTANT:"),
        ("ä¸­æ–‡åˆ†æ", "USER: The image: <|image|> è¯·ç”¨ä¸­æ–‡åˆ†æè¿™å¼ é£å…‰ç…§ç‰‡çš„ä¼˜ç¼ºç‚¹ã€‚ ASSISTANT:"),
    ]
    
    # å¯¹æ¯å¼ å›¾ç‰‡è¿›è¡Œå•å›¾åˆ†æ
    print("\n" + "=" * 70)
    print("ğŸ“· å•å›¾åˆ†ææµ‹è¯•")
    print("=" * 70)
    
    for i, (img, filename) in enumerate(zip(images, filenames)):
        print(f"\n{'â”€' * 70}")
        print(f"ğŸ“· {filename}")
        print(f"{'â”€' * 70}")
        
        for prompt_name, prompt in single_image_prompts:
            print(f"\n  ğŸ”¸ {prompt_name}")
            
            start = time.time()
            try:
                response = model.chat(prompt, [img], max_new_tokens=200)
                elapsed = time.time() - start
                print(f"     â±ï¸ {elapsed:.1f}s")
                print(f"     ğŸ“ {response}")
            except Exception as e:
                elapsed = time.time() - start
                print(f"     âŒ Error ({elapsed:.1f}s): {e}")
    
    # å›¾ç‰‡å¯¹æ¯”æµ‹è¯•ï¼ˆå¦‚æœæœ‰å¤šå¼ å›¾ï¼‰
    if len(images) >= 2:
        print("\n\n" + "=" * 70)
        print("ğŸ”„ åŒå›¾å¯¹æ¯”æµ‹è¯•")
        print("=" * 70)
        
        compare_prompt = "USER: The first image: <|image|>\nThe second image: <|image|>\nWhich image has better quality? Compare their technical quality, composition, and aesthetic appeal. ASSISTANT:"
        
        # åªå¯¹æ¯”å‡ ç»„
        comparisons = [
            (0, 1),
            (0, 2) if len(images) > 2 else None,
            (2, 3) if len(images) > 3 else None,
        ]
        
        for pair in comparisons:
            if pair is None:
                continue
            i, j = pair
            print(f"\n{'â”€' * 70}")
            print(f"ğŸ”„ å¯¹æ¯”: {filenames[i]} vs {filenames[j]}")
            print(f"{'â”€' * 70}")
            
            start = time.time()
            try:
                response = model.chat(compare_prompt, [images[i], images[j]], max_new_tokens=300)
                elapsed = time.time() - start
                print(f"  â±ï¸ {elapsed:.1f}s")
                print(f"  ğŸ“ {response}")
            except Exception as e:
                elapsed = time.time() - start
                print(f"  âŒ Error ({elapsed:.1f}s): {e}")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    for temp_file in temp_files:
        if os.path.exists(temp_file):
            os.remove(temp_file)
    
    print("\n\nâœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()
