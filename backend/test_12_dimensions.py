#!/usr/bin/env python3
"""
é£å…‰æ‘„å½± 12 ç»´åº¦è¯„åˆ†æµ‹è¯•
2 æ ¸å¿ƒ + 10 é£å…‰ä¸“å±ç»´åº¦
"""

import os
import sys
import time
from pathlib import Path
from PIL import Image
import torch

sys.path.insert(0, str(Path(__file__).parent))
from raw_converter import is_raw_file, raw_to_jpeg
from one_align_scorer import OneAlignScorer

def prepare_image(image_path: str) -> tuple[str, bool]:
    """å‡†å¤‡å›¾ç‰‡"""
    if not is_raw_file(image_path):
        return image_path, False

    import tempfile
    temp_path = os.path.join(
        tempfile.gettempdir(),
        f"test_12d_{os.path.basename(image_path)}.jpg"
    )
    extracted = raw_to_jpeg(image_path, temp_path)

    img = Image.open(extracted)
    max_size = 1920
    w, h = img.size
    if w > max_size or h > max_size:
        ratio = min(max_size / w, max_size / h)
        img = img.resize((int(w * ratio), int(h * ratio)), Image.Resampling.LANCZOS)
        img.save(extracted, "JPEG", quality=95)

    return extracted, True


# é£å…‰æ‘„å½± 12 ç»´åº¦
LANDSCAPE_DIMENSIONS = [
    # æ ¸å¿ƒ (2)
    ("quality", "è´¨é‡"),
    ("aesthetics", "ç¾å­¦"),
    # æŠ€æœ¯å…³é”® (4)
    ("sharpness", "é”åº¦"),
    ("exposure", "æ›å…‰"),
    ("dynamic range", "åŠ¨æ€èŒƒå›´"),
    ("clarity", "æ¸…æ™°åº¦"),
    # æ„å›¾å…³é”® (2)
    ("composition", "æ„å›¾"),
    ("visual flow", "è§†è§‰æµåŠ¨"),
    # å…‰çº¿è‰²å½© (3)
    ("lighting", "å…‰çº¿"),
    ("color harmony", "è‰²å½©å’Œè°"),
    ("contrast", "å¯¹æ¯”åº¦"),
    # æƒ…æ„Ÿ (1)
    ("atmosphere", "æ°›å›´"),
]


def main():
    test_dir = "/Users/jameszhenyu/Desktop/NEWTEST/4"
    
    # æ”¶é›†å›¾ç‰‡
    extensions = {".jpg", ".jpeg", ".png", ".arw", ".cr2", ".cr3", ".nef", ".dng", ".raf"}
    image_files = []
    for f in os.listdir(test_dir):
        if os.path.splitext(f)[1].lower() in extensions:
            image_files.append(os.path.join(test_dir, f))
    
    print(f"\nğŸ“ æµ‹è¯•ç›®å½•: {test_dir}")
    print(f"   æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡")
    print(f"   æµ‹è¯•ç»´åº¦: {len(LANDSCAPE_DIMENSIONS)} ä¸ª\n")
    
    # åŠ è½½æ¨¡å‹
    scorer = OneAlignScorer()
    scorer.load_model()
    model = scorer.model
    
    print(f"\n{'='*80}")
    print("ğŸ”ï¸  é£å…‰æ‘„å½± 12 ç»´åº¦è¯„åˆ†æµ‹è¯•")
    print(f"{'='*80}\n")
    
    all_results = {}
    
    for img_path in image_files:
        filename = os.path.basename(img_path)
        print(f"\n{'â”€'*80}")
        print(f"ğŸ“· {filename}")
        print(f"{'â”€'*80}")
        
        processed_path, is_temp = prepare_image(img_path)
        if is_temp:
            print("   [RAWâ†’JPEG æå–]")
        
        image = Image.open(processed_path).convert("RGB")
        
        scores = {}
        start_total = time.time()
        
        with torch.inference_mode():
            for task_en, task_cn in LANDSCAPE_DIMENSIONS:
                start = time.time()
                score = model.score([image], task_=task_en, input_="image")
                score_value = float(score[0]) if isinstance(score, (list, torch.Tensor)) else float(score)
                elapsed = time.time() - start
                scores[task_en] = (score_value, task_cn, elapsed)
        
        total_time = time.time() - start_total
        
        # æ¸…ç†
        if is_temp and os.path.exists(processed_path):
            os.remove(processed_path)
        
        # è¾“å‡ºç»“æœ
        print(f"\n   {'ç»´åº¦':<15} {'ä¸­æ–‡':<10} {'åˆ†æ•°':>8} {'ç™¾åˆ†åˆ¶':>8}")
        print(f"   {'â”€'*50}")
        
        for task_en, (score, task_cn, _) in scores.items():
            bar = "â–ˆ" * int(score * 4)
            print(f"   {task_en:<15} {task_cn:<10} {score:>6.2f}/5  {score*20:>5.0f}/100  {bar}")
        
        # è®¡ç®—ç»¼åˆåˆ†
        core_score = (scores["quality"][0] * 0.4 + scores["aesthetics"][0] * 0.6) * 20
        avg_all = sum(s[0] for s in scores.values()) / len(scores) * 20
        
        print(f"\n   â±ï¸  æ€»è€—æ—¶: {total_time:.1f}s ({total_time/len(LANDSCAPE_DIMENSIONS):.2f}s/ç»´åº¦)")
        print(f"   ğŸ“Š æ ¸å¿ƒåŠ æƒåˆ† (Q40%+A60%): {core_score:.1f}/100")
        print(f"   ğŸ“Š 12ç»´åº¦å¹³å‡åˆ†: {avg_all:.1f}/100")
        
        all_results[filename] = {
            "scores": scores,
            "total_time": total_time,
            "core_score": core_score,
            "avg_all": avg_all,
        }
    
    # æ±‡æ€»
    print(f"\n\n{'='*80}")
    print("ğŸ“Š æ±‡æ€»")
    print(f"{'='*80}\n")
    
    print(f"{'æ–‡ä»¶å':<45} {'æ ¸å¿ƒåˆ†':>8} {'12ç»´å‡åˆ†':>8} {'è€—æ—¶':>8}")
    print(f"{'â”€'*75}")
    
    for filename, data in all_results.items():
        print(f"{filename:<45} {data['core_score']:>6.1f}  {data['avg_all']:>8.1f}  {data['total_time']:>6.1f}s")
    
    # æ€»æ—¶é—´
    total_all = sum(d["total_time"] for d in all_results.values())
    avg_per_image = total_all / len(all_results)
    print(f"\næ€»è€—æ—¶: {total_all:.1f}s | å¹³å‡: {avg_per_image:.1f}s/å¼  | {avg_per_image/len(LANDSCAPE_DIMENSIONS):.2f}s/ç»´åº¦")


if __name__ == "__main__":
    main()
