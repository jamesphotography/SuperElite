#!/usr/bin/env python3
"""
One-Align å®Œæ•´åˆ†æèƒ½åŠ›æµ‹è¯•
æµ‹è¯•æ¨¡å‹é™¤äº†æ‰“åˆ†ä¹‹å¤–è¿˜èƒ½æä¾›ä»€ä¹ˆä¿¡æ¯
"""

import os
import sys
import time
from pathlib import Path
from PIL import Image
import torch

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent))

from raw_converter import is_raw_file, raw_to_jpeg

def prepare_image(image_path: str) -> tuple[str, bool]:
    """å‡†å¤‡å›¾ç‰‡ (RAW æå–é¢„è§ˆ)"""
    if not is_raw_file(image_path):
        return image_path, False

    import tempfile
    temp_path = os.path.join(
        tempfile.gettempdir(),
        f"test_analysis_{os.path.basename(image_path)}.jpg"
    )
    extracted = raw_to_jpeg(image_path, temp_path)

    # è°ƒæ•´åˆ° 1920px
    img = Image.open(extracted)
    max_size = 1920
    w, h = img.size
    if w > max_size or h > max_size:
        ratio = min(max_size / w, max_size / h)
        img = img.resize((int(w * ratio), int(h * ratio)), Image.Resampling.LANCZOS)
        img.save(extracted, "JPEG", quality=95)

    return extracted, True


def load_one_align_model():
    """åŠ è½½ One-Align æ¨¡å‹"""
    print("=" * 70)
    print("ğŸš€ åŠ è½½ One-Align æ¨¡å‹...")
    print("=" * 70)
    
    from transformers import AutoModelForCausalLM
    
    # åŠ è½½æ¨¡å‹
    model = AutoModelForCausalLM.from_pretrained(
        "q-future/one-align",
        trust_remote_code=True,
        torch_dtype=torch.float16,
        device_map="mps"
    )
    
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ\n")
    return model


def run_analysis(model, image_path: str, prompts: list[tuple[str, str]]) -> dict:
    """
    è¿è¡Œå¤šä¸ªåˆ†ææç¤º
    
    Args:
        model: One-Align æ¨¡å‹
        image_path: å›¾ç‰‡è·¯å¾„
        prompts: [(name, prompt), ...] æç¤ºåˆ—è¡¨
    
    Returns:
        {name: (result, time), ...}
    """
    results = {}
    
    for name, prompt in prompts:
        print(f"  ğŸ“ {name}...", end=" ", flush=True)
        start = time.time()
        
        try:
            result = model.chat(
                image=image_path,
                msg=prompt,
                input_ids=None,
                max_new_tokens=512,
                do_sample=False,
            )
            elapsed = time.time() - start
            results[name] = (result, elapsed)
            print(f"({elapsed:.1f}s)")
        except Exception as e:
            elapsed = time.time() - start
            results[name] = (f"ERROR: {e}", elapsed)
            print(f"âŒ ({elapsed:.1f}s)")
    
    return results


def main():
    # æµ‹è¯•ç›®å½•
    test_dir = "/Users/jameszhenyu/Desktop/NEWTEST/4"
    
    # æ”¶é›†å›¾ç‰‡
    extensions = {".jpg", ".jpeg", ".png", ".arw", ".cr2", ".cr3", ".nef", ".dng", ".raf"}
    image_files = []
    for f in os.listdir(test_dir):
        if os.path.splitext(f)[1].lower() in extensions:
            image_files.append(os.path.join(test_dir, f))
    
    print(f"\nğŸ“ æµ‹è¯•ç›®å½•: {test_dir}")
    print(f"   æ‰¾åˆ° {len(image_files)} å¼ å›¾ç‰‡\n")
    
    # åŠ è½½æ¨¡å‹
    model = load_one_align_model()
    
    # å®šä¹‰æ‰€æœ‰æµ‹è¯•æç¤º - æ¦¨å¹²æ¨¡å‹èƒ½åŠ›ï¼
    analysis_prompts = [
        # === åŸºç¡€è¯„åˆ† ===
        ("Quality Score", "Rate the quality of this image. Output a score between 0-100."),
        ("Aesthetic Score", "Rate the aesthetic of this image. Output a score between 0-100."),
        
        # === æŠ€æœ¯åˆ†æ ===
        ("Technical Analysis", 
         "Analyze the technical aspects of this photograph: sharpness, noise level, exposure, dynamic range, color accuracy, and any optical issues like distortion or chromatic aberration."),
        
        ("Focus Quality", 
         "Evaluate the focus quality of this image. Is the main subject sharp? Is there any motion blur or camera shake? Describe the depth of field."),
        
        ("Exposure Analysis", 
         "Analyze the exposure of this photograph. Are there blown highlights or crushed shadows? Is the histogram well balanced? Suggest any exposure corrections."),
        
        # === æ„å›¾åˆ†æ ===
        ("Composition Analysis", 
         "Analyze the composition of this photograph. Consider: rule of thirds, leading lines, symmetry, framing, visual balance, foreground/background relationship, and use of negative space."),
        
        ("Visual Flow", 
         "Describe how the eye moves through this image. What draws attention first? Is there a clear visual hierarchy? Are there any distracting elements?"),
        
        # === å…‰çº¿åˆ†æ ===
        ("Lighting Analysis", 
         "Analyze the lighting in this photograph: type of light (natural/artificial), direction, quality (hard/soft), color temperature, and how it shapes the subject."),
        
        ("Golden Hour Assessment", 
         "Is this image shot during golden hour, blue hour, or other special lighting conditions? How does the light quality affect the mood?"),
        
        # === è‰²å½©åˆ†æ ===
        ("Color Analysis", 
         "Analyze the color palette of this image: dominant colors, color harmony, saturation levels, and emotional impact of the colors."),
        
        ("Color Grading Suggestions", 
         "Suggest color grading improvements for this image. What adjustments to hue, saturation, or tone would enhance the visual impact?"),
        
        # === æƒ…æ„Ÿä¸é£æ ¼ ===
        ("Mood & Atmosphere", 
         "Describe the mood and atmosphere of this photograph. What emotions does it evoke? Is it peaceful, dramatic, melancholic, joyful?"),
        
        ("Photography Style", 
         "Identify the photography style and genre of this image. Is it landscape, portrait, street, documentary, fine art, commercial? What stylistic influences do you see?"),
        
        # === ä¸»ä½“ä¸åœºæ™¯ ===
        ("Subject Description", 
         "Describe in detail what is depicted in this photograph. What is the main subject? What is in the foreground, midground, and background?"),
        
        ("Scene Classification", 
         "Classify this scene: sunset, sunrise, night, aurora, cityscape, seascape, mountain, forest, desert, architecture, wildlife, portrait, street, macro, abstract, etc."),
        
        # === ç»¼åˆè¯„ä»· ===
        ("Strengths", 
         "List the main strengths of this photograph. What makes it stand out? What has the photographer done well?"),
        
        ("Weaknesses", 
         "List any weaknesses or areas for improvement in this photograph. Be constructive and specific."),
        
        ("Improvement Suggestions", 
         "Provide specific suggestions to improve this photograph, both in-camera (composition, timing, settings) and in post-processing."),
        
        # === ç”¨é€”å»ºè®® ===
        ("Usage Recommendations", 
         "What would this image be suitable for? Portfolio, stock photography, fine art print, social media, editorial, commercial use?"),
        
        # === ä¸­æ–‡æµ‹è¯• ===
        ("ä¸­æ–‡ç»¼åˆè¯„ä»·", 
         "è¯·ç”¨ä¸­æ–‡è¯¦ç»†åˆ†æè¿™å¼ ç…§ç‰‡çš„ä¼˜ç¼ºç‚¹ï¼ŒåŒ…æ‹¬æ„å›¾ã€å…‰çº¿ã€è‰²å½©ã€æŠ€æœ¯è´¨é‡ç­‰æ–¹é¢ï¼Œå¹¶ç»™å‡ºå…·ä½“çš„æ”¹è¿›å»ºè®®ã€‚"),
    ]
    
    # å¤„ç†æ¯å¼ å›¾ç‰‡
    all_results = {}
    
    for img_path in image_files:
        filename = os.path.basename(img_path)
        print("\n" + "=" * 70)
        print(f"ğŸ“· å¤„ç†: {filename}")
        print("=" * 70)
        
        # å‡†å¤‡å›¾ç‰‡
        processed_path, is_temp = prepare_image(img_path)
        print(f"   {'[RAWâ†’JPEG æå–]' if is_temp else '[ç›´æ¥è¯»å–]'}")
        
        # è¿è¡Œæ‰€æœ‰åˆ†æ
        start_total = time.time()
        results = run_analysis(model, processed_path, analysis_prompts)
        total_time = time.time() - start_total
        
        all_results[filename] = {
            "results": results,
            "total_time": total_time,
        }
        
        # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
        if is_temp and os.path.exists(processed_path):
            os.remove(processed_path)
        
        print(f"\nâ±ï¸  æ€»è€—æ—¶: {total_time:.1f}s ({total_time/len(analysis_prompts):.1f}s/é¡¹)")
    
    # è¾“å‡ºè¯¦ç»†æŠ¥å‘Š
    print("\n\n")
    print("=" * 70)
    print("ğŸ“Š å®Œæ•´åˆ†ææŠ¥å‘Š")
    print("=" * 70)
    
    for filename, data in all_results.items():
        print(f"\n\n{'#' * 70}")
        print(f"# {filename}")
        print(f"# æ€»è€—æ—¶: {data['total_time']:.1f}s")
        print(f"{'#' * 70}")
        
        for name, (result, elapsed) in data["results"].items():
            print(f"\n--- {name} ({elapsed:.1f}s) ---")
            print(result)
    
    # æ—¶é—´ç»Ÿè®¡
    print("\n\n")
    print("=" * 70)
    print("â±ï¸  æ—¶é—´ç»Ÿè®¡æ±‡æ€»")
    print("=" * 70)
    
    for filename, data in all_results.items():
        print(f"\n{filename}:")
        for name, (_, elapsed) in data["results"].items():
            print(f"  {name}: {elapsed:.1f}s")
        print(f"  ---")
        print(f"  æ€»è®¡: {data['total_time']:.1f}s")


if __name__ == "__main__":
    main()
