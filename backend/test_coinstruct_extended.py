#!/usr/bin/env python3
"""
æµ‹è¯• co-instruct çš„æ‰©å±•èƒ½åŠ›
- åœºæ™¯æè¿°
- å…³é”®å­—ç”Ÿæˆ
- åœºæ™¯åˆ†ç±»
- æ‹æ‘„æ—¶é—´/åœ°ç‚¹æ¨æ–­
- æƒ…ç»ª/æ°›å›´æè¿°
"""

import os
import sys
import time
from pathlib import Path
from PIL import Image
import torch

sys.path.insert(0, str(Path(__file__).parent))
from raw_converter import is_raw_file, raw_to_jpeg


def prepare_image(image_path: str) -> tuple[str, bool]:
    """å‡†å¤‡å›¾ç‰‡"""
    if not is_raw_file(image_path):
        return image_path, False

    import tempfile
    temp_path = os.path.join(
        tempfile.gettempdir(),
        f"test_ext_{os.path.basename(image_path)}.jpg"
    )
    extracted = raw_to_jpeg(image_path, temp_path)

    img = Image.open(extracted)
    max_size = 1920
    w, h = img.size
    if w > max_size or h > max_size:
        ratio = min(max_size / w, max_size / h)
        img = img.resize((int(w * ratio), int(h * ratio)), Image.Resampling.LANCZOS)
        img.save(extracted, "JPEG", quality=95)

    return extracted, True


def main():
    test_dir = "/Users/jameszhenyu/Desktop/NEWTEST/4"
    
    # åªç”¨ JPG æµ‹è¯•
    jpg_file = None
    for f in os.listdir(test_dir):
        if f.lower().endswith('.jpg'):
            jpg_file = os.path.join(test_dir, f)
            break
    
    if not jpg_file:
        # ç”¨ç¬¬ä¸€å¼ å›¾
        for f in os.listdir(test_dir):
            ext = os.path.splitext(f)[1].lower()
            if ext in {".jpg", ".jpeg", ".png", ".arw", ".cr2", ".cr3", ".nef", ".dng", ".raf"}:
                jpg_file = os.path.join(test_dir, f)
                break
    
    print(f"\nğŸ“· æµ‹è¯•å›¾ç‰‡: {os.path.basename(jpg_file)}\n")
    
    # åŠ è½½æ¨¡å‹
    print("=" * 70)
    print("ğŸš€ åŠ è½½ co-instruct æ¨¡å‹...")
    print("=" * 70)
    
    from transformers import AutoModelForCausalLM
    
    model = AutoModelForCausalLM.from_pretrained(
        "q-future/co-instruct",
        trust_remote_code=True,
        torch_dtype=torch.float16,
        attn_implementation="eager",
        device_map={"": "mps"}
    )
    
    print("âœ… æ¨¡å‹åŠ è½½å®Œæˆ\n")
    
    # å‡†å¤‡å›¾ç‰‡
    processed_path, is_temp = prepare_image(jpg_file)
    image = Image.open(processed_path).convert("RGB")
    print(f"   {'[RAWâ†’JPEG]' if is_temp else '[ç›´æ¥è¯»å–]'}")
    
    # æ‰©å±•èƒ½åŠ›æµ‹è¯•
    extended_prompts = [
        # === åœºæ™¯æè¿° ===
        ("åœºæ™¯æè¿° (EN)", 
         "USER: The image: <|image|> Describe what you see in this photograph in detail. Include the subject, setting, and any notable elements. ASSISTANT:"),
        
        ("åœºæ™¯æè¿° (ä¸­æ–‡)", 
         "USER: The image: <|image|> è¯·è¯¦ç»†æè¿°è¿™å¼ ç…§ç‰‡ä¸­çš„åœºæ™¯ã€‚ ASSISTANT:"),
        
        # === å…³é”®å­—ç”Ÿæˆ ===
        ("å…³é”®å­— (EN)", 
         "USER: The image: <|image|> Generate 10 keywords that describe this photograph. List them separated by commas. ASSISTANT:"),
        
        ("å…³é”®å­— (ä¸­æ–‡)", 
         "USER: The image: <|image|> ä¸ºè¿™å¼ ç…§ç‰‡ç”Ÿæˆ10ä¸ªæè¿°æ€§å…³é”®è¯ï¼Œç”¨é€—å·åˆ†éš”ã€‚ ASSISTANT:"),
        
        # === åœºæ™¯åˆ†ç±» ===
        ("åœºæ™¯åˆ†ç±»", 
         "USER: The image: <|image|> Classify this photograph into one category: sunset, sunrise, aurora, night/starry, waterfall, mountain, ocean/seascape, cityscape, forest, desert, wildlife, portrait, street. Answer with one word. ASSISTANT:"),
        
        ("æ‹æ‘„ç±»å‹", 
         "USER: The image: <|image|> What type of photography is this: landscape, portrait, wildlife, architecture, street, macro, aerial, underwater? Answer with one word. ASSISTANT:"),
        
        # === æ—¶é—´/åœ°ç‚¹æ¨æ–­ ===
        ("æ‹æ‘„æ—¶é—´", 
         "USER: The image: <|image|> What time of day was this photo taken: sunrise/golden hour, morning, midday, afternoon, sunset/golden hour, blue hour, night? ASSISTANT:"),
        
        ("å¯èƒ½åœ°ç‚¹", 
         "USER: The image: <|image|> Where do you think this photograph was taken? Describe the likely location or region. ASSISTANT:"),
        
        # === æƒ…ç»ª/æ°›å›´ ===
        ("æƒ…ç»ªæ°›å›´", 
         "USER: The image: <|image|> Describe the mood and atmosphere of this photograph in 2-3 words. ASSISTANT:"),
        
        ("æƒ…æ„Ÿæ ‡ç­¾", 
         "USER: The image: <|image|> What emotion does this photograph evoke? Choose from: peaceful, dramatic, mysterious, joyful, melancholic, awe-inspiring, romantic, energetic. ASSISTANT:"),
        
        # === æŠ€æœ¯ä¿¡æ¯æ¨æ–­ ===
        ("æ‹æ‘„è®¾å¤‡æ¨æµ‹", 
         "USER: The image: <|image|> Based on the image quality and characteristics, guess what camera type was used: smartphone, mirrorless, DSLR, drone, action camera? ASSISTANT:"),
        
        ("ç„¦æ®µæ¨æµ‹", 
         "USER: The image: <|image|> Estimate the focal length used: ultra-wide (14-24mm), wide (24-35mm), standard (35-50mm), short telephoto (70-135mm), telephoto (200mm+)? ASSISTANT:"),
        
        # === æ ‡é¢˜ç”Ÿæˆ ===
        ("è‹±æ–‡æ ‡é¢˜", 
         "USER: The image: <|image|> Create a poetic title for this photograph in 3-5 words. ASSISTANT:"),
        
        ("ä¸­æ–‡æ ‡é¢˜", 
         "USER: The image: <|image|> ä¸ºè¿™å¼ ç…§ç‰‡åˆ›ä½œä¸€ä¸ªå¯Œæœ‰è¯—æ„çš„ä¸­æ–‡æ ‡é¢˜ï¼Œ3-5ä¸ªå­—ã€‚ ASSISTANT:"),
        
        # === ç¤¾äº¤åª’ä½“ ===
        ("Instagram æ–‡æ¡ˆ", 
         "USER: The image: <|image|> Write a short Instagram caption for this photograph with relevant hashtags. ASSISTANT:"),
    ]
    
    print("\n" + "=" * 70)
    print("ğŸ§ª æ‰©å±•èƒ½åŠ›æµ‹è¯•")
    print("=" * 70)
    
    results = {}
    
    for prompt_name, prompt in extended_prompts:
        print(f"\n{'â”€' * 60}")
        print(f"ğŸ”¸ {prompt_name}")
        
        start = time.time()
        try:
            response = model.chat(prompt, [image], max_new_tokens=150)
            elapsed = time.time() - start
            
            # åªæå–æ–‡æœ¬éƒ¨åˆ†
            if hasattr(response, 'cpu'):
                response_text = str(response)
            else:
                response_text = response
            
            print(f"   â±ï¸ {elapsed:.1f}s")
            print(f"   ğŸ“ {response_text}")
            
            results[prompt_name] = {
                "response": response_text,
                "time": elapsed,
            }
            
        except Exception as e:
            elapsed = time.time() - start
            print(f"   âŒ Error ({elapsed:.1f}s): {e}")
            results[prompt_name] = {"error": str(e), "time": elapsed}
    
    # æ¸…ç†
    if is_temp and os.path.exists(processed_path):
        os.remove(processed_path)
    
    # ç»Ÿè®¡
    print("\n\n" + "=" * 70)
    print("ğŸ“Š æµ‹è¯•ç»Ÿè®¡")
    print("=" * 70)
    
    success = sum(1 for r in results.values() if "error" not in r)
    total_time = sum(r["time"] for r in results.values())
    
    print(f"   æˆåŠŸ: {success}/{len(results)}")
    print(f"   æ€»è€—æ—¶: {total_time:.1f}s")
    print(f"   å¹³å‡: {total_time/len(results):.1f}s/é—®é¢˜")


if __name__ == "__main__":
    main()
